---
title: "SMekala_Assign5"
author: "Sekhar Mekala"
date: "Thursday, September 24, 2015"
output: html_document
---

##Problem set 1

Given that **$$ A = \mbox{} \left[ \begin{array}{ccc} 1 & 0 \\ 1 & 1 \\ 1 & 3 \\ 1 & 4 \end{array} \right]$$** 

and **$$ b = \mbox{} \left[ \begin{array}{ccc} 0 \\ 8 \\ 8 \\ 20 \end{array} \right]$$** 

The following R code computes $AA^T$ and $A^Tb$

```{r}

A = matrix(c(1,0,1,1,1,3,1,4), byrow = T, nrow = 4)

print(A)

b = matrix(c(0,8,8,20), byrow = T, nrow = 4)
print(b)

#Finding transpose(A) . A
t(A) %*% A

#Finding transpose(A) . b
t(A) %*% b
```

To find $\hat{x}$, we have to use the following formula:

$$\hat{x} = (A^T A)^{-1} A^T b$$

Here is the R code to find the $\hat{x}$

```{r}
x_hat <- solve(t(A) %*% A) %*% (t(A) %*% b)
print(x_hat)

```

To find the error vector (represented as $\bar{\varepsilon}$) is given by the following equation:

$$\bar{\varepsilon} = b - A \hat{x}$$

Here is the R Code to find the error vector: $\bar{\varepsilon}$

```{r}
error <- b - (A %*% x_hat)
print(error)
```

The square of the error is given by 

$$||\bar{\varepsilon}^2|| = ||(b - A \hat{x})^2||$$

The following R code computes the squared error:

```{r}
sum(error^2)

```

Hence the error is $||\bar{\varepsilon}||$ is $\sqrt{44} = 6.63325$

Given that **$p = \mbox{} \left[ \begin{array}{ccc} 1 \\ 5 \\ 13 \\ 17 \end{array} \right]$**

If we use $p$ in the place of $b$, then $\hat{x}$ and error will be the following (the R code and its output are given below):

```{r}
p <- matrix(c(1,5,13, 17), byrow = T, nrow = 4)

x_hat <- solve(t(A) %*% A) %*% (t(A) %*% p)
print(x_hat)


error <- p - (A %*% x_hat)

print(error)
```

The error is **zero**, if we use $p$ matrix in the place of $b$.

Hence using linear regression, we can model the given system of equations $Ax = b$ (shown below) using the equation $b = x + 4y$. 

**$$ A = \mbox{} \left[ \begin{array}{ccc} 1 & 0 \\ 1 & 1 \\ 1 & 3 \\ 1 & 4 \end{array} \right]$$** 

and **$$ b = \mbox{} \left[ \begin{array}{ccc} 0 \\ 8 \\ 8 \\ 20 \end{array} \right]$$** 

Let us find $b - p$

```{r}
e = b - p

error <- b - (A %*% x_hat)

```
The computed $e$ is same as the error vector, which we obtained earlier($\bar{\varepsilon}$ for $A$ and $b$)

Let us show that $e$ is orthogonal to $p$. If the dot product of $e$ and $p$ is zero, then they are orthogonal. The dot product of $e$ and $p$ is given below:

```{r}
sum(e * p)
```

The above result shows that $e$ and $p$ are orthogonal


##Problem set 2
Reading the file's data into a data frame:

```{r}
df <- read.csv("auto-mpg.data", header = F, sep = "")
head(df)
nrow(df)
names(df)
```

The above display confirms that we have successfully read 392 records from the file into the **df** data frame. But the column names of the data frame are randomly assigned. Let us give proper column names:

```{r}
names(df) <- c("displacement", "horsepower", "weight", "acceleration","mpg")
```

Now let us create the $A$ and $b$ matries:

```{r}

#Creating A and b matrices
A <- as.matrix(cbind(df[1], df[2], df[3], df[4]))
b <- as.matrix(df[5])

#Displaying some rows of both A and B

head(A)
head(b)

#typeof(A)
#solve(t(A) %*% A)
```

To find $\hat{x}$, we have to use the following formula:

$$\hat{x} = (A^T A)^{-1} A^T b$$

Here is the R code to find the $\hat{x}$

```{r}
x_hat <- solve(t(A) %*% A) %*% (t(A) %*% b)
print(x_hat)
```

So as per linear regression, we can model $mpg$ using the following equation:

$$mpg = - 0.030037938 displacement + 0.157115685 horsepower - 0.006217883 weight + 1.997320955 acceleration$$

I verified the above result using the **lsfit()**, as shown in the following R code:

**NOTE:** The **lsfit()** can generate a linear regression model without an intercept (unlike the **lm()** function)

```{r}
ls_fit <- lsfit(A, b, wt = NULL, intercept = F)
ls_fit$coefficients
```

Hence our model is correct, since we obtained the same equation using the built in function **lsfit()**

Let us determine the **error**:

The error is computed by the following formula:

$$||\bar{\varepsilon}|| = ||(b - A \hat{x})||$$

R code to find the error follows:

```{r}
error <- b - (A %*% x_hat)
head(error)
sqrt(sum(error^2))

```

The above R code found the error vector $\bar{\varepsilon}$, and also computed the error, the $||\bar{\varepsilon}||$ as 114.4615

Let us find how good our fit is. We will plot the residual plot (plot between the predicted and the actual values), and also find the $r^2$ value:


```{r}
plot(b,error, xlab = "actual", ylab = "predicted")
```
**Figure 1: Residual plot**

The residual plot has some pattern (but not strong), and this confirms that there is some potential to test some other models and improve the fit. The $r^2$  (the ***coefficient of determination***) value is also around 71.43399%, which is good. But, we may improve this by checking other models or by eliminating insignificant variables. Given the scope of the assignment, I am not evaluating other models.

The R code to find the $r^2$ is given below:

```{r}
100 * var(A %*% x_hat)/var(b)

```

The $r^2$ is calculated as $100 * var(predicted) / var(actual)$


                                               ~~~** End of Assignment **~~~